<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>TrÃ² chÆ¡i chá»n ngÆ°á»i tráº£ bÃ i</title>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <style>
      body {
        font-family: Arial, sans-serif;
        text-align: center;
        background: #f0f0f0;
      }
      #wrapper {
        position: relative;
        display: inline-block;
      }
      video,
      canvas {
        width: 720px;
        height: 560px;
      }
      canvas {
        position: absolute;
        top: 0;
        left: 0;
      }
      #pickBtn {
        margin-top: 20px;
        font-size: 18px;
        padding: 10px 20px;
      }
      #result {
        margin-top: 15px;
        font-size: 20px;
        font-weight: bold;
      }
    </style>
  </head>
  <body>
    <h2>ğŸ¯ TrÃ² chÆ¡i chá»n ngÆ°á»i tráº£ bÃ i báº±ng webcam</h2>

    <div id="wrapper">
      <video id="video" autoplay muted></video>
      <canvas id="overlay"></canvas>
    </div>

    <br />
    <button id="pickBtn">ğŸ§™ Chá»n ngáº«u nhiÃªn ngÆ°á»i tráº£ bÃ i</button>
    <h3 id="result"></h3>

    <script>
      const video = document.getElementById('video');
      const canvas = document.getElementById('overlay');
      const context = canvas.getContext('2d');
      const resultText = document.getElementById('result');
      const pickBtn = document.getElementById('pickBtn');

      let detections = [];

      // Load face-api model tá»« github chÃ­nh chá»§
      const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';

      Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
      ]).then(startVideo);

      async function startVideo() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
          video.srcObject = stream;
        } catch (err) {
          alert('KhÃ´ng thá»ƒ truy cáº­p webcam ğŸ˜¥');
          console.error(err);
        }
      }

      video.addEventListener('play', () => {
        const displaySize = { width: video.width, height: video.height };
        faceapi.matchDimensions(canvas, displaySize);

        setInterval(async () => {
          const detectionsAll = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
          detections = faceapi.resizeResults(detectionsAll, displaySize);

          context.clearRect(0, 0, canvas.width, canvas.height);

          detections.forEach((detection, i) => {
            const box = detection.box;
            context.strokeStyle = 'red';
            context.lineWidth = 2;
            context.strokeRect(box.x, box.y, box.width, box.height);
            context.fillStyle = 'yellow';
            context.font = '18px Arial';
            context.fillText(`NgÆ°á»i #${i + 1}`, box.x, box.y - 10);
          });
        }, 500);
      });

      pickBtn.addEventListener('click', () => {
        if (detections.length === 0) {
          resultText.textContent = 'âš ï¸ KhÃ´ng cÃ³ ai Ä‘á»ƒ gá»i háº¿t ğŸ˜…';
          return;
        }
        const pick = Math.floor(Math.random() * detections.length);
        resultText.textContent = `ğŸ‰ NgÆ°á»i pháº£i tráº£ bÃ i lÃ  ğŸ‘‰ NgÆ°á»i #${pick + 1}`;
      });
    </script>
  </body>
</html>
